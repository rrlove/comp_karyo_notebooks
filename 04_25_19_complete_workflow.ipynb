{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I want to recapitulate all the steps necessary to reproduce the paper results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### converting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shell commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### first, I had to merge the phase 2 files with the VObs files. then I had to convert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### first I had to make the VObs files: I kept only those sites present in phase 2, and removed certain specimens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I'll work on compiling all that in a separate file, and right now, will compile the Python steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDing training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "from collections import namedtuple\n",
    "import datetime\n",
    "import h5py\n",
    "import ingenos\n",
    "import itertools\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in data for 2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_2R, g_2R = ingenos.import_data(\n",
    "    \"/afs/crc.nd.edu/group/BesanskyNGS2/inversion_genotyping/merged_p2_and_VObs_2R.h5\", \"2R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in data for 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_2L = \"/afs/crc.nd.edu/group/BesanskyNGS/inversion_genotyping/merged_p2_and_VObs_2L.h5\"\n",
    "chrom_2L = \"2L\"\n",
    "\n",
    "callset_2L = h5py.File(path_2L, mode='r')[chrom_2L]\n",
    "\n",
    "v_2L = allel.VariantChunkedTable(callset_2L['variants'], index='POS',\n",
    "                                names=['POS','REF','ALT','DP','MQ','QD','numalt'])\n",
    "\n",
    "g_2L = allel.GenotypeChunkedArray(callset_2L['calldata']['GT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### note to self: add the metadata files without the PCA or computational karyotypes-- before I ran the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88eacb3d7ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmd_2L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../metadata/all_samples_2L_metadata_080318.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmd_2R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../metadata/all_samples_2R_metadata_080318.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "md_2L = pd.read_csv(\"../metadata/all_samples_2L_metadata_080318.csv\", sep=\"\\t\")\n",
    "md_2R = pd.read_csv(\"../metadata/all_samples_2R_metadata_080318.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create filters to keep the correct partitions for each inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_outliers = ((md_2R[\"country\"] != \"Kenya\") &\n",
    "                (md_2R[\"country\"] != \"Gambia, The\") &\n",
    "                (md_2R[\"country\"] != \"Guinea-Bissau\")).values\n",
    "\n",
    "west = (md_2R[\"country\"] != \"Kenya\").values\n",
    "\n",
    "j_bool = ((md_2R[\"country\"] != \"Kenya\") & (md_2R[\"country\"] != \"Gambia, The\") &\\\n",
    "          (md_2R[\"country\"] != \"Guinea-Bissau\") & (md_2R[\"country\"] != \"France\") &\\\n",
    "         (md_2R[\"species\"] == \"An. gambiae\")).values\n",
    "\n",
    "col_bool = ( (md_2R[\"ox_code\"].isin(md_2R.loc[non_outliers,\"ox_code\"])) &\\\n",
    "                 (md_2R[\"species\"] == \"An. coluzzii\"))\n",
    "\n",
    "gam_bool = ( (md_2R[\"ox_code\"].isin(md_2R.loc[non_outliers,\"ox_code\"])) &\\\n",
    "                 (md_2R[\"species\"] == \"An. gambiae\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2La"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2La, model_2La = ingenos.run_pca(\"2La\", v_2L, g_2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2La, model_2La, 0, 1, ax, md_2L,\n",
    "                region = \"2La\", label_with = \"2La\",\n",
    "               alpha = 0.5, title = \"2La\")\n",
    "\n",
    "ax.text( -375, 150, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 0, 150, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 350, 150, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axvline(x = -200, color = 'k', linewidth = 1)\n",
    "ax.axvline(x = 200, color = 'k', linewidth = 1)\n",
    "plt.title(\"2La\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2La\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2La_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2La = []\n",
    "\n",
    "PC1 = coords_2La[:, 0]\n",
    "PC2 = coords_2La[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC1[i] <= -200:\n",
    "        \n",
    "        PCA_2La.append(0)\n",
    "        \n",
    "    elif PC1[i] > -200 and PC1[i] <= 200:\n",
    "        \n",
    "        PCA_2La.append(1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        PCA_2La.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2Rj, model_2Rj = ingenos.run_pca(\"2Rj\", v_2R, g_2R, samples_bool=j_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2Rj, model_2Rj, 0, 1, ax, md_2R[j_bool],\n",
    "                region = \"2Rj\", label_with = \"2Rj\",\n",
    "               alpha = 0.5, title = \"2Rj\")\n",
    "\n",
    "ax.text( -50, 100, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 185, 100, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 275, 100, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axvline(x = 150, color = 'k', linewidth = 1)\n",
    "ax.axvline(x = 225, color = 'k', linewidth = 1)\n",
    "\n",
    "plt.title(\"2Rj\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2Rj\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2Rj_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2Rj = []\n",
    "\n",
    "PC1 = coords_2Rj[:, 0]\n",
    "PC2 = coords_2Rj[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC1[i] <= 150:\n",
    "        \n",
    "        PCA_2Rj.append(0)\n",
    "        \n",
    "    elif PC1[i] > 150 and PC1[i] <= 225:\n",
    "        \n",
    "        PCA_2Rj.append(1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        PCA_2Rj.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2Rb, model_2Rb = ingenos.run_pca(\"2Rb\", v_2R, g_2R, samples_bool = west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2Rb, model_2Rb, 0, 1, ax, md_2R[west],\n",
    "                region = \"2Rb\", label_with = \"2Rb\",\n",
    "               alpha = 0.5, title = \"2Rb\")\n",
    "\n",
    "ax.text( -150, 75, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 80, 75, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 210, 75, \"2\", fontsize = 20, weight = 'bold')\n",
    "ax.text( -175, -85, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 0, -85, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 175, -85, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axhline(y = -60, color = 'k', linewidth = 1)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "plt.vlines(-100, ymin, -60, color='k', linewidth = 1)\n",
    "plt.vlines(100, ymin, -60, color='k', linewidth = 1)\n",
    "plt.vlines(0, ymax, -60, color='k', linewidth = 1)\n",
    "plt.vlines(150, ymax, -60, color='k', linewidth = 1)\n",
    "\n",
    "ax.set_ylim(bottom=ymin, top=ymax)\n",
    "\n",
    "plt.title(\"2Rb\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2Rb\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2Rb_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2Rb = []\n",
    "\n",
    "PC1 = coords_2Rb[:, 0]\n",
    "PC2 = coords_2Rb[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC2[i] <= -60:\n",
    "        \n",
    "        if PC1[i] <= -100:\n",
    "            \n",
    "            PCA_2Rb.append(0)\n",
    "            \n",
    "        elif PC1[i] > -100 and PC1[i] <= 100:\n",
    "            \n",
    "            PCA_2Rb.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            PCA_2Rb.append(2)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if PC1[i] <= 0:\n",
    "            \n",
    "            PCA_2Rb.append(0)\n",
    "            \n",
    "        elif PC1[i] > 0 and PC1[i] <= 150:\n",
    "            \n",
    "            PCA_2Rb.append(1)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            PCA_2Rb.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2Rc, model_2Rc = ingenos.run_pca(\"2Rc\", v_2R, g_2R, samples_bool=non_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2Rc, model_2Rc, 0, 1, ax, md_2R[non_outliers],\n",
    "                region = \"2Rc\", label_with = \"2Rc\",\n",
    "               alpha = 0.5, title = \"2Rc\")\n",
    "\n",
    "ax.text( -50, 25, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( -50, -60, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( -50, -175, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axhline(y = -25, color = 'k', linewidth = 1)\n",
    "ax.axhline(y = -75, color = 'k', linewidth = 1)\n",
    "\n",
    "plt.title(\"2Rc\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2Rc\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2Rc_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2Rc = []\n",
    "\n",
    "PC1 = coords_2Rc[:, 0]\n",
    "PC2 = coords_2Rc[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC2[i] > -25:\n",
    "        \n",
    "        PCA_2Rc.append(0)\n",
    "        \n",
    "    elif PC2[i] <= -25 and PC2[i] > -75:\n",
    "        \n",
    "        PCA_2Rc.append(1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        PCA_2Rc.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for 2Rd, we excluded the distal part of the inversion from the PCA to get a signal less influenced by the overlapping 2Ru inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sites_expression = '( (POS > 41000000) & (POS < 42375004) )'\n",
    "\n",
    "d_sites_bool = v_2R.eval(d_sites_expression)\n",
    "\n",
    "np.sum(d_sites_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_Rd_alt_alleles, two_Rd_which_alleles = ingenos.filter_and_convert_genotypes(g_2R,\n",
    "                                            sites_boolean = d_sites_bool,\n",
    "                                            samples_boolean = gam_bool,\n",
    "                                            min_count = 3,\n",
    "                                            variance_threshold = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2Rd, model_2Rd = allel.stats.pca(two_Rd_alt_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2Rd, model_2Rd, 0, 1, ax, md_2R[j_bool],\n",
    "                region = \"2Rd\", label_with = \"2Rd\",\n",
    "               alpha = 0.5, title = \"2Rd\")\n",
    "\n",
    "ax.text( 150, 10, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 150, -100, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( 150, -200, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axhline(y = -50, color = 'k', linewidth = 1)\n",
    "ax.axhline(y = -150, color = 'k', linewidth = 1)\n",
    "\n",
    "plt.title(\"2Rd\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2Rd\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2Rd_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2Rd = []\n",
    "\n",
    "PC1 = coords_2Rd[:, 0]\n",
    "PC2 = coords_2Rd[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC2[i] >= -50:\n",
    "        \n",
    "        PCA_2Rd.append(0)\n",
    "        \n",
    "    elif PC2[i] < -50 and PC2[i] > -150:\n",
    "        \n",
    "        PCA_2Rd.append(1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        PCA_2Rd.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords_2Ru, model_2Ru = ingenos.run_pca(\"2Ru\", v_2R, g_2R, samples_bool=non_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "sns.despine(ax = ax, offset = 10)\n",
    "ingenos.plot_pca_coords(coords_2Ru, model_2Ru, 0, 1, ax, md_2R[non_outliers],\n",
    "                region = \"2Ru\", label_with = \"2Ru\",\n",
    "               alpha = 0.5, title = \"2Ru\")\n",
    "\n",
    "ax.text( -40, 0, \"0\", fontsize = 20, weight = 'bold')\n",
    "ax.text( -40, 100, \"1\", fontsize = 20, weight = 'bold')\n",
    "ax.text( -40, 200, \"2\", fontsize = 20, weight = 'bold')\n",
    "\n",
    "ax.axhline(y = 150, color = 'k', linewidth = 1)\n",
    "ax.axhline(y = 50, color = 'k', linewidth = 1)\n",
    "\n",
    "plt.title(\"2Ru\", fontsize=20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "legend = ax.legend(title = \"Cytogenetic\\n 2Ru\", fontsize=15)\n",
    "legend.get_title().set_fontsize('15')\n",
    "\n",
    "#plt.savefig(ingenos.make_date_stamp(\"../data/results/2Ru_karyotyping_PCA\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_2Ru = []\n",
    "\n",
    "PC1 = coords_2Ru[:, 0]\n",
    "PC2 = coords_2Ru[:, 1]\n",
    "\n",
    "assert len(PC1) == len(PC2), \"Components are somehow different lengths\"\n",
    "\n",
    "for i in range(len(PC1)):\n",
    "    \n",
    "    if PC2[i] >= 150:\n",
    "        \n",
    "        PCA_2Ru.append(2)\n",
    "        \n",
    "    elif PC2[i] < 150 and PC2[i] > 50:\n",
    "        \n",
    "        PCA_2Ru.append(1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        PCA_2Ru.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### merge these in to the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md_2L[\"new_PCA_2La\"] = pd.Series(PCA_2La).values\n",
    "\n",
    "md_2R.loc[(md_2R[\"country\"] != \"Kenya\"),\"new_PCA_2Rb\"] = pd.Series(PCA_2Rb).values\n",
    "\n",
    "md_2R.loc[non_outliers,\"new_PCA_2Rc\"] = pd.Series(PCA_2Rc).values\n",
    "md_2R.loc[non_outliers,\"new_PCA_2Ru\"] = pd.Series(PCA_2Ru).values\n",
    "\n",
    "md_2R.loc[j_bool,\"new_PCA_2Rj\"] = pd.Series(PCA_2Rj).values\n",
    "md_2R.loc[j_bool,\"new_PCA_2Rd\"] = pd.Series(PCA_2Rd).values\n",
    "\n",
    "md_2L.fillna(value=\"None\", inplace=True)\n",
    "md_2R.fillna(value=\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDing tag SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in the identifications of each specimen to either the training or the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = np.load(\"../metadata/comp_karyo_splits/splits.npy\").flat[0]\n",
    "\n",
    "splits_d = np.load(\"../metadata/comp_karyo_splits/2Rdj_splits.npy\",\n",
    "                allow_pickle=True).flat[0]\n",
    "\n",
    "splits[\"2Rd\"] = splits_d[\"2Rd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### include the code for generating one's own splits if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### subset to specimens that could be called for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_2La = pd.DataFrame(md_2L)\n",
    "md_2Rj = md_2R.loc[md_2R[\"new_PCA_2Rj\"] != \"None\",:]\n",
    "md_2Rb = md_2R.loc[md_2R[\"new_PCA_2Rb\"] != \"None\",:]\n",
    "md_2Rc = md_2R.loc[md_2R[\"new_PCA_2Rc\"] != \"None\",:]\n",
    "md_2Rd = md_2R.loc[md_2R[\"new_PCA_2Rd\"] != \"None\",:]\n",
    "md_2Ru = md_2R.loc[md_2R[\"new_PCA_2Ru\"] != \"None\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_splits = {\"2Rb\" : {}, \"2Rc\" : {}, \"2La\" : {}, \"2Rd\" : {}, \"2Ru\" : {}, \"2Rj\" : {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_splits[\"2La\"][\"train\"], own_splits[\"2La\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2La[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2La[\"new_PCA_2La\"].values)\n",
    "\n",
    "own_splits[\"2Rj\"][\"train\"], own_splits[\"2Rj\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rj[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rj[\"new_PCA_2Rj\"].values)\n",
    "\n",
    "own_splits[\"2Rb\"][\"train\"], own_splits[\"2Rb\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rb[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rb[\"new_PCA_2Rb\"].values)\n",
    "\n",
    "own_splits[\"2Rc\"][\"train\"], own_splits[\"2Rc\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rc[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rc[\"new_PCA_2Rc\"].values)\n",
    "\n",
    "own_splits[\"2Rd\"][\"train\"], own_splits[\"2Rd\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rd[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rd[\"new_PCA_2Rd\"].values)\n",
    "\n",
    "own_splits[\"2Ru\"][\"train\"], own_splits[\"2Ru\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Ru[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Ru[\"new_PCA_2Ru\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mask low-quality genotypes. We don't do this for PCA, because the results depend on thousands of SNPs. When identifying tag SNPs, however, individual SNPs are the focus and we need to exclude those of low quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2R = h5py.File(\n",
    "    \"/afs/crc.nd.edu/group/BesanskyNGS2/inversion_genotyping/merged_p2_and_VObs_2R.h5\", \n",
    "    mode=\"r\")\n",
    "\n",
    "gq_2R = merged_2R[\"2R\"]['calldata']['GQ'][:]\n",
    "\n",
    "g_2R.mask = gq_2R < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gq_2L = callset_2L['calldata']['GQ'][:]\n",
    "\n",
    "g_2L.mask = gq_2L < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2La"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2La = ingenos.construct_filter_expression(\"2La\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2La = v_2L.eval(sites_2La)\n",
    "\n",
    "np.sum(filter_2La)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2La = g_2L.subset(sel1 = md_2L[\"ox_code\"].isin(splits[\"2La\"][\"train\"]).values)\n",
    "\n",
    "md_2La = md_2L.loc[md_2L[\"ox_code\"].isin(splits[\"2La\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2La[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2La[\"new_PCA_2La\"].values)\n",
    "    \n",
    "    train_bool = md_2La[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2La[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    a = ingenos.run_concordance_calculation(\"2La\", v_2L[:], g_2La, \n",
    "                                md_2La.loc[train_bool, \"new_PCA_2La\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2La,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = a.loc[((a[\"called_0\"] > 0.9) & (a[\"called_1\"] > 0.9) & (a[\"called_2\"] > 0.9) &\\\n",
    "       (a[\"min\"] > 0.995)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2L[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2La.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2La_test = pd.DataFrame(md_2La.loc[test_bool,:])\n",
    "    \n",
    "    md_2La_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2La_test[\"assigned\"] != md_2La_test[\"new_PCA_2La\"])\n",
    "    \n",
    "    a_dict[i] = (train, test, a, top, mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### average the ten iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    a_compiled.extend(a_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_average = pd.DataFrame({\"position\" : sorted(set(a_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(a_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = a_dict[i][2][a_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    a_average = a_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rj = ingenos.construct_filter_expression(\"2Rj\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rj = v_2R.eval(sites_2Rj)\n",
    "\n",
    "np.sum(filter_2Rj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rj = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"train\"]).values)\n",
    "\n",
    "md_2Rj = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rj[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rj[\"new_PCA_2Rj\"].values)\n",
    "    \n",
    "    train_bool = md_2Rj[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rj[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    j = ingenos.run_concordance_calculation(\"2Rj\", v_2R[:], g_2Rj, \n",
    "                                md_2Rj.loc[train_bool, \"new_PCA_2Rj\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rj,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = j.loc[((j[\"called_0\"] > 0.9) & (j[\"called_1\"] > 0.9) & (j[\"called_2\"] > 0.9) &\\\n",
    "       (j[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rj.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rj_test = pd.DataFrame(md_2Rj.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rj_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rj_test[\"assigned\"].map(float).map(str) != md_2Rj_test[\"new_PCA_2Rj\"])\n",
    "    \n",
    "    j_dict[i] = (train, test, j, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    j_compiled.extend(j_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_average = pd.DataFrame({\"position\" : sorted(set(j_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(j_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = j_dict[i][2][j_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    j_average = j_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rb = ingenos.construct_filter_expression(\"2Rb\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rb = v_2R.eval(sites_2Rb)\n",
    "\n",
    "np.sum(filter_2Rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rb = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"train\"]).values)\n",
    "\n",
    "md_2Rb = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rb[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rb[\"new_PCA_2Rb\"].values)\n",
    "    \n",
    "    train_bool = md_2Rb[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rb[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    b = ingenos.run_concordance_calculation(\"2Rb\", v_2R[:], g_2Rb, \n",
    "                                md_2Rb.loc[train_bool, \"new_PCA_2Rb\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rb,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = b.loc[((b[\"called_0\"] > 0.9) & (b[\"called_1\"] > 0.9) & (b[\"called_2\"] > 0.9) &\\\n",
    "       (b[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rb.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rb_test = pd.DataFrame(md_2Rb.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rb_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rb_test[\"assigned\"].map(float).map(str) != md_2Rb_test[\"new_PCA_2Rb\"])\n",
    "    \n",
    "    b_dict[i] = (train, test, b, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    b_compiled.extend(b_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_average = pd.DataFrame({\"position\" : sorted(set(b_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(b_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = b_dict[i][2][b_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    b_average = b_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we identified concordant SNPs separetely in coluzzii and gambiae in 2Rc. in addition, we dropped specimens that carried 2Ru in gambiae from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rc = ingenos.construct_filter_expression(\"2Rc\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rc = v_2R.eval(sites_2Rc)\n",
    "\n",
    "np.sum(filter_2Rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rc = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"train\"]).values)\n",
    "\n",
    "md_2Rc = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### coluzzii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_bool = (md_2Rc[\"species\"] == \"An. coluzzii\").values\n",
    "\n",
    "col_c = g_2Rc.subset(sel1 = col_bool)\n",
    "\n",
    "col_md = md_2Rc.loc[col_bool,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(col_md[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=col_md[\"new_PCA_2Rc\"].values)\n",
    "    \n",
    "    train_bool = col_md[\"ox_code\"].isin(train).values\n",
    "    test_bool = col_md[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    col_c_conc = ingenos.run_concordance_calculation(\"2Rc\", v_2R[:], col_c, \n",
    "                                col_md.loc[train_bool, \"new_PCA_2Rc\"].map(int).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rc,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = col_c_conc.loc[((col_c_conc[\"called_0\"] > 0.9) &\\\n",
    "                     (col_c_conc[\"called_1\"] > 0.9) &\\\n",
    "                     (col_c_conc[\"called_2\"] > 0.9) &\\\n",
    "       (col_c_conc[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = col_c.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    col_md_test = pd.DataFrame(col_md.loc[test_bool,:])\n",
    "    \n",
    "    col_md_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(col_md_test[\"assigned\"].map(str) != col_md_test[\"new_PCA_2Rc\"])\n",
    "    \n",
    "    col_c_dict[i] = (train, test, col_c_conc, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    col_c_compiled.extend(col_c_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_average = pd.DataFrame({\"position\" : sorted(set(col_c_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = col_c_dict[i][2][col_c_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "    \n",
    "    #print(pos, mean_row)\n",
    "    \n",
    "    col_c_average = col_c_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gambiae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_trim_bool = ((md_2Rc[\"species\"] == \"An. gambiae\") &\\\n",
    "                 (md_2Rc[\"new_PCA_2Rj\"] != \"2.0\") &\\\n",
    "                 (md_2Rc[\"ox_code\"] != \"AZ0267-C\") &\\\n",
    "                (md_2Rc[\"ox_code\"] != \"AV0043-C\")).values\n",
    "\n",
    "gam_c = g_2Rc.subset(sel1 = gam_trim_bool)\n",
    "\n",
    "gam_md = md_2Rc.loc[gam_trim_bool,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(gam_md[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=gam_md[\"new_PCA_2Rc\"].values)\n",
    "    \n",
    "    train_bool = gam_md[\"ox_code\"].isin(train).values\n",
    "    test_bool = gam_md[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    gam_c_conc = ingenos.run_concordance_calculation(\"2Rc\", v_2R[:], gam_c, \n",
    "                                gam_md.loc[train_bool, \"new_PCA_2Rc\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rc,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = gam_c_conc.loc[((gam_c_conc[\"called_0\"] > 0.9) &\\\n",
    "                     (gam_c_conc[\"called_1\"] > 0.9) &\\\n",
    "                     (gam_c_conc[\"called_2\"] > 0.9) &\\\n",
    "       (gam_c_conc[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = gam_c.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    gam_md_test = pd.DataFrame(gam_md.loc[test_bool,:])\n",
    "    \n",
    "    gam_md_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(gam_md_test[\"assigned\"].map(str) != gam_md_test[\"new_PCA_2Rc\"])\n",
    "    \n",
    "    gam_c_dict[i] = (train, test, gam_c_conc, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    gam_c_compiled.extend(gam_c_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_average = pd.DataFrame({\"position\" : sorted(set(gam_c_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(gam_c_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = gam_c_dict[i][2][gam_c_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "    \n",
    "    #print(pos, mean_row)\n",
    "    \n",
    "    gam_c_average = gam_c_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for identifying concordant SNPs in 2Rd, we use the entire inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rd = '( (POS > 31495381) & (POS < 42375004) )'\n",
    "\n",
    "filter_2Rd = v_2R.eval(sites_2Rd)\n",
    "\n",
    "np.sum(filter_2Rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rd = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"train\"]).values)\n",
    "\n",
    "md_2Rd = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rd[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rd[\"new_PCA_2Rd\"].values)\n",
    "    \n",
    "    train_bool = md_2Rd[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rd[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    d = ingenos.run_concordance_calculation(\"2Rd\", v_2R[:], g_2Rd, \n",
    "                                md_2Rd.loc[train_bool, \"new_PCA_2Rd\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rd,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = d.loc[((d[\"called_0\"] > 0.9) & (d[\"called_1\"] > 0.9) & (d[\"called_2\"] > 0.9) &\\\n",
    "       (d[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rd.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rd_test = pd.DataFrame(md_2Rd.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rd_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rd_test[\"assigned\"].map(float).map(str) != md_2Rd_test[\"new_PCA_2Rd\"])\n",
    "    \n",
    "    d_dict[i] = (train, test, d, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    d_compiled.extend(d_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_average = pd.DataFrame({\"position\" : sorted(set(d_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(d_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = d_dict[i][2][d_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    d_average = d_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Ru = ingenos.construct_filter_expression(\"2Ru\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Ru = v_2R.eval(sites_2Ru)\n",
    "\n",
    "np.sum(filter_2Ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Ru = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"train\"]).values)\n",
    "\n",
    "md_2Ru = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Ru[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Ru[\"new_PCA_2Ru\"].values)\n",
    "    \n",
    "    train_bool = md_2Ru[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Ru[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    u = ingenos.run_concordance_calculation(\"2Ru\", v_2R[:], g_2Ru, \n",
    "                                md_2Ru.loc[train_bool, \"new_PCA_2Ru\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Ru,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = u.loc[((u[\"called_0\"] > 0.9) & (u[\"called_1\"] > 0.9) & (u[\"called_2\"] > 0.9) &\\\n",
    "       (u[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Ru.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Ru_test = pd.DataFrame(md_2Ru.loc[test_bool,:])\n",
    "    \n",
    "    md_2Ru_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Ru_test[\"assigned\"].map(str) != md_2Ru_test[\"new_PCA_2Ru\"])\n",
    "    \n",
    "    u_dict[i] = (train, test, u, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    u_compiled.extend(u_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_average = pd.DataFrame({\"position\" : sorted(set(u_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(u_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = u_dict[i][2][u_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    u_average = u_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### take the top SNPs for each inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_top = a_average.loc[((a_average[\"called_0\"] > 0.9) & (a_average[\"called_1\"] > 0.9) &\\\n",
    "                       (a_average[\"called_2\"] > 0.9) &\\\n",
    "               (a_average[\"min\"] > 0.995) & (a_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_top = j_average.loc[((j_average[\"called_0\"] > 0.9) & (j_average[\"called_1\"] > 0.9) &\\\n",
    "                       (j_average[\"called_2\"] > 0.9) &\\\n",
    "               (j_average[\"min\"] > 0.8) & (j_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_top = b_average.loc[((b_average[\"called_0\"] > 0.9) & (b_average[\"called_1\"] > 0.9) &\\\n",
    "                       (b_average[\"called_2\"] > 0.9) &\\\n",
    "               (b_average[\"min\"] > 0.8) & (b_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_col_top = col_average.loc[((col_average[\"called_0\"] > 0.9) &\\\n",
    "                             (col_average[\"called_1\"] > 0.9) &\\\n",
    "                         (col_average[\"called_2\"] > 0.9) &\\\n",
    "               (col_average[\"min\"] > 0.8) & (col_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_gam_top = gam_average.loc[((gam_average[\"called_0\"] > 0.9) &\\\n",
    "                             (gam_average[\"called_1\"] > 0.9) &\\\n",
    "                         (gam_average[\"called_2\"] > 0.9) &\\\n",
    "               (gam_average[\"min\"] > 0.8) & (gam_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_top = d_average.loc[((d_average[\"called_0\"] > 0.9) & (d_average[\"called_1\"] > 0.9) &\\\n",
    "                       (d_average[\"called_2\"] > 0.9) &\\\n",
    "               (d_average[\"min\"] > 0.8) & (d_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_top = u_average.loc[((u_average[\"called_0\"] > 0.9) & (u_average[\"called_1\"] > 0.9) &\\\n",
    "                       (u_average[\"called_2\"] > 0.9) &\\\n",
    "               (u_average[\"min\"] > 0.8) & (u_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing in validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### subset the data and the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2La = g_2L.subset(sel1 = md_2L[\"ox_code\"].isin(splits[\"2La\"][\"test\"]).values)\n",
    "g_2Rj = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"test\"]).values)\n",
    "g_2Rb = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"test\"]).values)\n",
    "g_2Rc = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"test\"]).values)\n",
    "g_2Rd = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"test\"]).values)\n",
    "g_2Ru = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"test\"]).values)\n",
    "\n",
    "md_2La = md_2L.loc[md_2L[\"ox_code\"].isin(splits[\"2La\"][\"test\"]),:]\n",
    "md_2Rb = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"test\"]),:]\n",
    "md_2Rc = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"test\"]),:]\n",
    "md_2Rd = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"test\"]),:]\n",
    "md_2Rj = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"test\"]),:]\n",
    "md_2Ru = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"test\"]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### then, subset by species for 2Rc. we also drop the Bamako specimens (Bamako is a chromosomal form defined by 2Rjcu == 2, with 2Rb polymorphic; in our data set, all gambiae specimens with 2Rj == 2 are Bamako, so we can use that as a shortcut); Bamako appears to be on an independent evolutionary trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rc = g_2Rc.subset(sel1 = md_2Rc[\"2Rj\"] != \"2.0\")\n",
    "md_2Rc = md_2Rc.loc[md_2Rc[\"2Rj\"] != \"2.0\",:]\n",
    "\n",
    "col_bool = (md_2Rc[\"species\"] == \"An. coluzzii\").values\n",
    "gam_bool = (md_2Rc[\"species\"] == \"An. gambiae\").values\n",
    "\n",
    "g_2Rc_col = g_2Rc.subset(sel1 = col_bool)\n",
    "g_2Rc_gam = g_2Rc.subset(sel1 = gam_bool)\n",
    "\n",
    "col_md = md_2Rc.loc[col_bool,:]\n",
    "gam_md = md_2Rc.loc[gam_bool,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inversion = namedtuple('Inversion',['SNPs','metadata','genotypes','inv_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_dict = {\"2La\" : Inversion(SNPs = a_top.values, metadata = md_2La, genotypes = g_2La,\n",
    "                             inv_title = \"new_PCA_2La\"),\n",
    "           \"2Rb\" : Inversion(SNPs = b_top.values, metadata = md_2Rb, genotypes = g_2Rb,\n",
    "                            inv_title = \"new_PCA_2Rb\"),\n",
    "            \"2Rc_col\" : Inversion(SNPs = c_col_top.values, metadata = col_md, \n",
    "                                 genotypes = g_2Rc_col,\n",
    "                             inv_title = \"new_PCA_2Rc\"),\n",
    "           \"2Rc_gam\" : Inversion(SNPs = c_gam_top.values, metadata = gam_md, \n",
    "                                genotypes = g_2Rc_gam,\n",
    "                            inv_title = \"new_PCA_2Rc\")\n",
    "           \"2Rd\" : Inversion(SNPs = d_top.values, metadata = md_2Rd, genotypes = g_2Rd,\n",
    "                            inv_title = \"new_PCA_2Rd\"),\n",
    "           \"2Rj\" : Inversion(SNPs = j_top.values, metadata = md_2Rj, genotypes = g_2Rj,\n",
    "                            inv_title = \"new_PCA_2Rj\"),\n",
    "           \"2Ru\" : Inversion(SNPs = u_top.values, metadata = md_2Ru, genotypes = g_2Ru,\n",
    "                            inv_title = \"new_PCA_2Ru\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for inversion in inv_dict.keys():\n",
    "    \n",
    "    ##set up objects\n",
    "    SNPs = inv_dict[inversion].SNPs\n",
    "    md = inv_dict[inversion].metadata\n",
    "    gt = inv_dict[inversion].genotypes[:]\n",
    "    col_name = inv_dict[inversion].inv_title\n",
    "    new_col_name = inversion + \"_assigned\"\n",
    "    mean_name = inversion + \"_means\"\n",
    "    \n",
    "    if inversion == \"2La\":\n",
    "        \n",
    "        vt = v_2L[:]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        vt = v_2R[:]\n",
    "    \n",
    "    ##identify sites found in the data\n",
    "    site_indices = []\n",
    "    \n",
    "    for site in SNPs:\n",
    "    \n",
    "        where = np.where(vt[\"POS\"] == site)\n",
    "        \n",
    "        if len(where[0]) > 0:\n",
    "                \n",
    "            site_indices.append(where[0][0])\n",
    "            \n",
    "    print(inversion, \"# targets: \", str(len(SNPs)), \" # found: \", str(len(site_indices)))\n",
    "    \n",
    "    ##identify biallelic sites\n",
    "    \n",
    "    bi_bool = gt.subset(sel0 = site_indices).count_alleles().max_allele() <= 1\n",
    "        \n",
    "    alts = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).to_n_alt()\n",
    "        \n",
    "    is_called = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).is_called()\n",
    "    \n",
    "    av_gts = np.mean(np.ma.MaskedArray(\n",
    "            alts, mask = ~is_called), axis=0).data\n",
    "            \n",
    "    total_sites = np.sum(is_called, axis=0)\n",
    "        \n",
    "    karyos = []\n",
    "    \n",
    "    for alt in av_gts:\n",
    "        \n",
    "        if alt <= (2/3):\n",
    "            \n",
    "            karyos.append(0)\n",
    "            \n",
    "        elif alt > (2/3) and alt <= (4/3):\n",
    "            \n",
    "            karyos.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            karyos.append(2)\n",
    "            \n",
    "    md[new_col_name] = karyos\n",
    "    md[mean_name] = av_gts\n",
    "    \n",
    "    mismatches = np.sum(md[new_col_name] != md[col_name].map(float).map(int))\n",
    "    \n",
    "    print(inversion, \" # mismatches: \", mismatches,\"\\n\")\n",
    "    print(av_gts)\n",
    "    print(total_sites,\"\\n\")\n",
    "\n",
    "for inversion in inv_dict.keys():\n",
    "    \n",
    "    ##set up objects\n",
    "    SNPs = inv_dict[inversion].SNPs\n",
    "    md = inv_dict[inversion].metadata\n",
    "    gt = inv_dict[inversion].genotypes[:]\n",
    "    col_name = inv_dict[inversion].inv_title\n",
    "    new_col_name = inversion + \"_assigned\"\n",
    "    mean_name = inversion + \"_means\"\n",
    "    called_name = inversion + \"_called\"\n",
    "    match_name = inversion + \"_sites_matching\"\n",
    "    match_proportion_name = inversion + \"_pct_sites_matching\"\n",
    "\n",
    "    if inversion == \"2La\":\n",
    "        \n",
    "        vt = v_2L[:]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        vt = v_2R[:]\n",
    "    \n",
    "    ##identify sites found in the data\n",
    "    site_indices = []\n",
    "    \n",
    "    for site in SNPs:\n",
    "    \n",
    "        where = np.where(vt[\"POS\"] == site)\n",
    "        \n",
    "        if len(where[0]) > 0:\n",
    "                \n",
    "            site_indices.append(where[0][0])\n",
    "            \n",
    "    print(inversion, \"# targets: \", str(len(SNPs)), \" # found: \", str(len(site_indices)))\n",
    "    \n",
    "    ##identify biallelic sites\n",
    "    \n",
    "    bi_bool = gt.subset(sel0 = site_indices).count_alleles().max_allele() <= 1\n",
    "        \n",
    "    alts = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).to_n_alt()\n",
    "        \n",
    "    is_called = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).is_called()\n",
    "    \n",
    "    av_gts = np.mean(np.ma.MaskedArray(\n",
    "            alts, mask = ~is_called), axis=0).data\n",
    "    \n",
    "    match_dict = {0: None, 1: None, 2: None}\n",
    "    \n",
    "    for value in [0,1,2]:\n",
    "    \n",
    "        n_matches = np.sum(np.ma.MaskedArray(alts, mask = ~is_called) == value, axis=0)\n",
    "        match_dict[value] = n_matches\n",
    "            \n",
    "    total_sites = np.sum(is_called, axis=0)\n",
    "        \n",
    "    karyos = []\n",
    "    \n",
    "    for alt in av_gts:\n",
    "        \n",
    "        if alt <= (2/3):\n",
    "            \n",
    "            karyos.append(0)\n",
    "            \n",
    "        elif alt > (2/3) and alt <= (4/3):\n",
    "            \n",
    "            karyos.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            karyos.append(2)\n",
    "            \n",
    "    match_list = []\n",
    "    \n",
    "    for index, karyo in enumerate(karyos):\n",
    "        \n",
    "        match_list.append(match_dict[karyo][index])\n",
    "            \n",
    "    md[new_col_name] = karyos\n",
    "    md[mean_name] = av_gts\n",
    "    md[called_name] = total_sites\n",
    "    md[match_name] = pd.Series(match_list)\n",
    "    md[match_proportion_name] = md[match_name] / md[called_name]\n",
    "    \n",
    "    print(inversion,\"\\n\")\n",
    "    print(av_gts)\n",
    "    print(total_sites,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### repeat for all specimens to karyotype them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dict = {\"2La\" : Inversion(SNPs = a_top.values, metadata = md_2L, genotypes = g_2L,\n",
    "                             inv_title = \"new_PCA_2La\"),\n",
    "            \"2Rj\" : Inversion(SNPs = j_top.values, metadata = md_2R, genotypes = g_2R,\n",
    "                            inv_title = \"new_PCA_2Rj\"),\n",
    "           \"2Rb\" : Inversion(SNPs = b_top.values, metadata = md_2R, genotypes = g_2R,\n",
    "                            inv_title = \"new_PCA_2Rb\"),\n",
    "            \"2Rc_col\" : Inversion(SNPs = c_col_top.values, metadata = md_2R, genotypes = g_2R,\n",
    "                            inv_title = \"new_PCA_2Rc\"),\n",
    "           \"2Rc_gam\" : Inversion(SNPs = c_gam_top.values, metadata = md_2R, genotypes = g_2R, \n",
    "                            inv_title = \"new_PCA_2Rc\"),\n",
    "           \"2Rd\" : Inversion(SNPs = d_top.values, metadata = md_2R, genotypes = g_2R,\n",
    "                            inv_title = \"new_PCA_2Rd\"),\n",
    "           \"2Ru\" : Inversion(SNPs = u_top.values, metadata = md_2R, genotypes = g_2R,\n",
    "                            inv_title = \"new_PCA_2Ru\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inversion in inv_dict.keys():\n",
    "    \n",
    "    ##set up objects\n",
    "    SNPs = inv_dict[inversion].SNPs\n",
    "    md = inv_dict[inversion].metadata\n",
    "    gt = inv_dict[inversion].genotypes[:]\n",
    "    col_name = inv_dict[inversion].inv_title\n",
    "    new_col_name = inversion + \"_assigned\"\n",
    "    mean_name = inversion + \"_means\"\n",
    "    called_name = inversion + \"_called\"\n",
    "    match_name = inversion + \"_sites_matching\"\n",
    "    match_proportion_name = inversion + \"_pct_sites_matching\"\n",
    "\n",
    "    if inversion == \"2La\":\n",
    "        \n",
    "        vt = v_2L[:]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        vt = v_2R[:]\n",
    "    \n",
    "    ##identify sites found in the data\n",
    "    site_indices = []\n",
    "    \n",
    "    for site in SNPs:\n",
    "    \n",
    "        where = np.where(vt[\"POS\"] == site)\n",
    "        \n",
    "        if len(where[0]) > 0:\n",
    "                \n",
    "            site_indices.append(where[0][0])\n",
    "            \n",
    "    print(inversion, \"# targets: \", str(len(SNPs)), \" # found: \", str(len(site_indices)))\n",
    "    \n",
    "    ##identify biallelic sites\n",
    "    \n",
    "    bi_bool = gt.subset(sel0 = site_indices).count_alleles().max_allele() <= 1\n",
    "        \n",
    "    alts = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).to_n_alt()\n",
    "        \n",
    "    is_called = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).is_called()\n",
    "    \n",
    "    av_gts = np.mean(np.ma.MaskedArray(\n",
    "            alts, mask = ~is_called), axis=0).data\n",
    "    \n",
    "    match_dict = {0: None, 1: None, 2: None}\n",
    "    \n",
    "    for value in [0,1,2]:\n",
    "    \n",
    "        n_matches = np.sum(np.ma.MaskedArray(alts, mask = ~is_called) == value, axis=0)\n",
    "        match_dict[value] = n_matches\n",
    "            \n",
    "    total_sites = np.sum(is_called, axis=0)\n",
    "        \n",
    "    karyos = []\n",
    "    \n",
    "    for alt in av_gts:\n",
    "        \n",
    "        if alt <= (2/3):\n",
    "            \n",
    "            karyos.append(0)\n",
    "            \n",
    "        elif alt > (2/3) and alt <= (4/3):\n",
    "            \n",
    "            karyos.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            karyos.append(2)\n",
    "            \n",
    "    match_list = []\n",
    "    \n",
    "    for index, karyo in enumerate(karyos):\n",
    "        \n",
    "        match_list.append(match_dict[karyo][index])\n",
    "            \n",
    "    md[new_col_name] = karyos\n",
    "    md[mean_name] = av_gts\n",
    "    md[called_name] = total_sites\n",
    "    md[match_name] = pd.Series(match_list)\n",
    "    md[match_proportion_name] = md[match_name] / md[called_name]\n",
    "    \n",
    "    print(inversion,\"\\n\")\n",
    "    print(av_gts)\n",
    "    print(total_sites,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing in low coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in and prepare data from Main et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### karyotypes taken from Main et al. 2015 supplemental file Molecular Ecology 2015 Main.xlsx, tab \"Fig1_genotype_data\"; VCF from Dryad [give doi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in and prepare metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Main_good_names = [\"02SEL85\",\"04SEL02\",\"04SEL14\",\"04SEL021\",\"04SEL18\",\"04SEL84\",\"04SEL91\",\n",
    "                   \"010sel134\",\"O10SEL160\",\n",
    "               \"2012SEL002\",\"2012SEL003\",\"2012SEL006\",\"2012SEL009\",\"2012sel012\",\n",
    "                   \"2012SEL013\",\"2012sel029\",\"2012sel063\"]\n",
    "\n",
    "Main_sample_bool = [sample in Main_good_names for sample in Main_2R[\"samples\"]]\n",
    "\n",
    "Main_a = [2,2,1,1,2,2,2,2,2,1,2,2,2,2,2,2,2]\n",
    "Main_b = [2,2,2,1,2,0,0,0,1,2,0,2,2,0,2,1,1]\n",
    "Main_c = [2,2,0,1,2,0,0,0,1,0,0,2,2,0,2,1,1]\n",
    "Main_d = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "Main_j = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "Main_u = [0,0,0,0,0,0,2,2,1,0,0,0,0,1,0,0,0]\n",
    "\n",
    "Main_md = pd.DataFrame({\"sample_ID\" : pd.Series(Main_2R[\"samples\"][Main_sample_bool]),\n",
    "                       \"2La\" : pd.Series(Main_a),\n",
    "                       \"2Rb\" : pd.Series(Main_b),\n",
    "                       \"2Rc\" : pd.Series(Main_c),\n",
    "                       \"2Rd\" : pd.Series(Main_d),\n",
    "                       \"2Rj\" : pd.Series(Main_j),\n",
    "                       \"2Ru\" : pd.Series(Main_u)})\n",
    "\n",
    "Main_md = Main_md[[\"sample_ID\",\"2La\",\"2Rb\",\"2Rc\",\"2Rd\",\"2Rj\",\"2Ru\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in data, filter, and mask low-quality genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Main_2L = allel.read_vcf(\n",
    "    '/afs/crc.nd.edu/group/BesanskyNGS/data05/comp_karyo/data/Agam_normfilt_vcfs.vcf.gz',\n",
    "                   fields = ['*'], region = \"2L\", types={'calldata/GQ': 'f4'})\n",
    "\n",
    "Main_2R = allel.read_vcf(\n",
    "    '/afs/crc.nd.edu/group/BesanskyNGS/data05/comp_karyo/data/Agam_normfilt_vcfs.vcf.gz',\n",
    "                   fields = ['*'], region = \"2R\", types={'calldata/GQ': 'f4'})\n",
    "\n",
    "\n",
    "Main_2R_gt = allel.GenotypeArray(Main_2R[\"calldata/GT\"]).subset(sel1 = Main_sample_bool)\n",
    "\n",
    "Main_2R_gq = Main_2R[\"calldata/GQ\"][:,Main_sample_bool]\n",
    "\n",
    "Main_2R_gt.mask = Main_2R_gq < 20\n",
    "\n",
    "Main_2L_gt = allel.GenotypeArray(Main_2L[\"calldata/GT\"]).subset(sel1 = Main_sample_bool)\n",
    "\n",
    "Main_2L_gq = Main_2L[\"calldata/GQ\"][:,Main_sample_bool]\n",
    "\n",
    "Main_2L_gt.mask = Main_2L_gq < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'namedtuple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-088aa55fa72d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mInversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inversion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SNPs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'genotypes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'inv_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'namedtuple' is not defined"
     ]
    }
   ],
   "source": [
    "Main_inv_dict = {\"2La\" : Inversion(SNPs = a_top.values, metadata = Main_md, \n",
    "                                   genotypes = Main_2L_gt, inv_title = \"2La\"),\n",
    "                 \"2Rj\" : Inversion(SNPs = j_top.values, metadata = Main_md, \n",
    "                             genotypes = Main_2R_gt, inv_title = \"2Rj\"),\n",
    "           \"2Rb\" : Inversion(SNPs = b_top.values, metadata = Main_md, \n",
    "                             genotypes = Main_2R_gt, inv_title = \"2Rb\"),\n",
    "        \"2Rc_col\" : Inversion(SNPs = col_top.values, metadata = Main_md, \n",
    "                               genotypes = Main_2R_gt, inv_title = \"2Rc\"),\n",
    "           \"2Rc_gam\" : Inversion(SNPs = gam_top.values, metadata = Main_md, \n",
    "                                  genotypes = Main_2R_gt, inv_title = \"2Rc\"),\n",
    "           \"2Rd\" : Inversion(SNPs = d_top.values, metadata = Main_md, \n",
    "                             genotypes = Main_2R_gt, inv_title = \"2Rd\"),\n",
    "           \"2Ru\" : Inversion(SNPs = u_top.values, metadata = Main_md, \n",
    "                             genotypes = Main_2R_gt, inv_title = \"2Ru\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for inversion in Main_inv_dict.keys():\n",
    "    \n",
    "    ##set up objects\n",
    "    SNPs = Main_inv_dict[inversion].SNPs\n",
    "    md = Main_inv_dict[inversion].metadata\n",
    "    gt = Main_inv_dict[inversion].genotypes\n",
    "    col_name = Main_inv_dict[inversion].inv_title\n",
    "    new_col_name = inversion + \"_assigned\"\n",
    "    mean_name = inversion + \"_means\"\n",
    "    sites_name = inversion + \"_sites_called\"\n",
    "    match_name = inversion + \"_sites_matching\"\n",
    "    match_proportion_name = inversion + \"_pct_sites_matching\"\n",
    "    \n",
    "    if inversion == \"2La\":\n",
    "        \n",
    "        pos = Main_2L[\"variants/POS\"]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        pos = Main_2R[\"variants/POS\"]\n",
    "    \n",
    "    ##identify sites found in the data\n",
    "    site_indices = []\n",
    "    \n",
    "    for site in SNPs:\n",
    "    \n",
    "        where = np.where(pos == site)\n",
    "        \n",
    "        if len(where[0]) > 0:\n",
    "                \n",
    "            site_indices.append(where[0][0])\n",
    "            \n",
    "    print(inversion, \"# targets: \", str(len(SNPs)), \" # found: \", str(len(site_indices)))\n",
    "    \n",
    "    ##identify biallelic sites\n",
    "    \n",
    "    bi_bool = gt.subset(sel0 = site_indices).count_alleles().max_allele() <= 1\n",
    "        \n",
    "    alts = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).to_n_alt()\n",
    "        \n",
    "    is_called = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).is_called()\n",
    "    \n",
    "    av_gts = np.mean(np.ma.MaskedArray(\n",
    "            alts, mask = ~is_called), axis=0).data\n",
    "    \n",
    "    match_dict = {0: None, 1: None, 2: None}\n",
    "    \n",
    "    for value in [0,1,2]:\n",
    "    \n",
    "        n_matches = np.sum(np.ma.MaskedArray(alts, mask = ~is_called) == value, axis=0)\n",
    "        match_dict[value] = n_matches\n",
    "    \n",
    "    total_sites = np.sum(is_called, axis=0)\n",
    "        \n",
    "    karyos = []\n",
    "    \n",
    "    for alt in av_gts:\n",
    "        \n",
    "        if alt <= (2/3):\n",
    "            \n",
    "            karyos.append(0)\n",
    "            \n",
    "        elif alt > (2/3) and alt <= (4/3):\n",
    "            \n",
    "            karyos.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            karyos.append(2)\n",
    "    \n",
    "    match_list = []\n",
    "    \n",
    "    for index, karyo in enumerate(karyos):\n",
    "        \n",
    "        match_list.append(match_dict[karyo][index])\n",
    "            \n",
    "    md[new_col_name] = pd.Series(karyos)\n",
    "    md[mean_name] = pd.Series(av_gts)\n",
    "    md[sites_name] = pd.Series(total_sites)\n",
    "    md[match_name] = pd.Series(match_list)\n",
    "    md[match_proportion_name] = md[match_name] / md[sites_name]\n",
    "    \n",
    "    mismatches = np.sum(md[new_col_name] != md[col_name])\n",
    "    \n",
    "    print(inversion, \" # mismatches: \", mismatches,\"\\n\")\n",
    "    print(av_gts)\n",
    "    print(total_sites,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### repeat with the Love et al. specimens. data from [doi], metadata from [file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### assemble the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Love_good_names = ['KL0218','KL0220','KL0231','KL0333','KL0341','KL0370','KL0671','KL0899']\n",
    "\n",
    "Love_a = [2,2,2,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "Love_b = [2,0,0,0,0,2,2,0]\n",
    "Love_c = [2,2,2,2,2,2,2,2]\n",
    "Love_d = [0,0,0,0,0,0,0,0]\n",
    "Love_j = [2,2,2,2,2,2,2,2]\n",
    "Love_u = [2,2,2,2,2,2,2,2]\n",
    "\n",
    "Love_md = pd.DataFrame({\"sample_ID\" : pd.Series(Love_good_names),\n",
    "                       \"2La\" : pd.Series(Love_a),\n",
    "                       \"2Rb\" : pd.Series(Love_b),\n",
    "                       \"2Rc\" : pd.Series(Love_c),\n",
    "                       \"2Rd\" : pd.Series(Love_d),\n",
    "                       \"2Rj\" : pd.Series(Love_j),\n",
    "                       \"2Ru\" : pd.Series(Love_u)})\n",
    "\n",
    "Love_md = Love_md[[\"sample_ID\",\"2La\",\"2Rb\",\"2Rc\",\"2Rd\",\"2Rj\",\"2Ru\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in the data, filter it, and mask low-quality genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Love_2R = allel.read_vcf(\n",
    "    '/afs/crc.nd.edu/group/BesanskyNGS/data02/16G_bamako/all.Bamakoset.2.recode.vcf.gz',\n",
    "                   fields = ['*'], region = \"2R\", types={'calldata/GQ': 'f4'})\n",
    "\n",
    "Love_2L = allel.read_vcf(\n",
    "    '/afs/crc.nd.edu/group/BesanskyNGS/data02/16G_bamako/all.Bamakoset.2.recode.vcf.gz',\n",
    "                   fields = ['*'], region = \"2L\", types={'calldata/GQ': 'f4'})\n",
    "\n",
    "Love_sample_bool = [sample in Love_good_names for sample in Love_2R[\"samples\"]]\n",
    "\n",
    "Love_2R_gt = allel.GenotypeArray(Love_2R[\"calldata/GT\"]).subset(sel1 = Love_sample_bool)\n",
    "Love_2R_gq = Love_2R[\"calldata/GQ\"][:,Love_sample_bool]\n",
    "\n",
    "Love_2R_gt.mask = Love_2R_gq < 20\n",
    "\n",
    "Love_2L_gt = allel.GenotypeArray(Love_2L[\"calldata/GT\"]).subset(sel1 = Love_sample_bool)\n",
    "\n",
    "Love_2L_gq = Love_2L[\"calldata/GQ\"][:,Love_sample_bool]\n",
    "\n",
    "Love_2L_gt.mask = Love_2L_gq < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Love_inv_dict = {\"2La\" : Inversion(SNPs = a_top.values, metadata = Love_md, \n",
    "                                   genotypes = Love_2L_gt, inv_title = \"2La\"),\n",
    "           \"2Rb\" : Inversion(SNPs = b_top.values, metadata = Love_md, \n",
    "                             genotypes = Love_2R_gt, inv_title = \"2Rb\"),\n",
    "            \"2Rc_col\" : Inversion(SNPs = col_top.values, metadata = Love_md, \n",
    "                                   genotypes = Love_2R_gt, inv_title = \"2Rc\"),\n",
    "           \"2Rc_gam\" : Inversion(SNPs = gam_top.values, metadata = Love_md, \n",
    "                                  genotypes = Love_2R_gt, inv_title = \"2Rc\"),\n",
    " \"2Rd\" : Inversion(SNPs = d_top.values, metadata = Love_md, \n",
    "                             genotypes = Love_2R_gt, inv_title = \"2Rd\"),\n",
    "           \"2Rj\" : Inversion(SNPs = j_top.values, metadata = Love_md, \n",
    "                             genotypes = Love_2R_gt, inv_title = \"2Rj\"),\n",
    "           \"2Ru\" : Inversion(SNPs = u_top.values, metadata = Love_md, \n",
    "                             genotypes = Love_2R_gt, inv_title = \"2Ru\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Love_inv_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-52c213f8b298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minversion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLove_inv_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m##set up objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSNPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLove_inv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minversion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNPs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLove_inv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minversion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Love_inv_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for inversion in Love_inv_dict.keys():\n",
    "    \n",
    "    ##set up objects\n",
    "    SNPs = Love_inv_dict[inversion].SNPs\n",
    "    md = Love_inv_dict[inversion].metadata\n",
    "    gt = Love_inv_dict[inversion].genotypes\n",
    "    col_name = Love_inv_dict[inversion].inv_title\n",
    "    new_col_name = inversion + \"_assigned\"\n",
    "    mean_name = inversion + \"_means\"\n",
    "    sites_name = inversion + \"_sites_called\"\n",
    "    match_name = inversion + \"_sites_matching\"\n",
    "    match_proportion_name = inversion + \"_pct_sites_matching\"\n",
    "    \n",
    "    if inversion == \"2La\":\n",
    "        \n",
    "        pos = Love_2L[\"variants/POS\"]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        pos = Love_2R[\"variants/POS\"]\n",
    "    \n",
    "    ##identify sites found in the data\n",
    "    site_indices = []\n",
    "    \n",
    "    for site in SNPs:\n",
    "    \n",
    "        where = np.where(pos == site)\n",
    "        \n",
    "        if len(where[0]) > 0:\n",
    "                \n",
    "            site_indices.append(where[0][0])\n",
    "            \n",
    "    print(inversion, \"# targets: \", str(len(SNPs)), \" # found: \", str(len(site_indices)))\n",
    "    \n",
    "    ##identify biallelic sites\n",
    "    \n",
    "    bi_bool = gt.subset(sel0 = site_indices).count_alleles().max_allele() <= 1\n",
    "        \n",
    "    alts = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).to_n_alt()\n",
    "        \n",
    "    is_called = gt.subset(sel0 = site_indices).subset(sel0 = bi_bool).is_called()\n",
    "    \n",
    "    av_gts = np.mean(np.ma.MaskedArray(\n",
    "            alts, mask = ~is_called), axis=0).data\n",
    "    \n",
    "    match_dict = {0: None, 1: None, 2: None}\n",
    "    \n",
    "    for value in [0,1,2]:\n",
    "    \n",
    "        n_matches = np.sum(np.ma.MaskedArray(alts, mask = ~is_called) == value, axis=0)\n",
    "        match_dict[value] = n_matches\n",
    "    \n",
    "    total_sites = np.sum(is_called, axis=0)\n",
    "        \n",
    "    karyos = []\n",
    "    \n",
    "    for alt in av_gts:\n",
    "        \n",
    "        if alt <= (2/3):\n",
    "            \n",
    "            karyos.append(0)\n",
    "            \n",
    "        elif alt > (2/3) and alt <= (4/3):\n",
    "            \n",
    "            karyos.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            karyos.append(2)\n",
    "    \n",
    "    match_list = []\n",
    "    \n",
    "    for index, karyo in enumerate(karyos):\n",
    "        \n",
    "        match_list.append(match_dict[karyo][index])\n",
    "            \n",
    "    md[new_col_name] = pd.Series(karyos)\n",
    "    md[mean_name] = pd.Series(av_gts)\n",
    "    md[sites_name] = pd.Series(total_sites)\n",
    "    md[match_name] = pd.Series(match_list)\n",
    "    md[match_proportion_name] = md[match_name] / md[sites_name]\n",
    "    \n",
    "    mismatches = np.sum(md[new_col_name] != md[col_name])\n",
    "    \n",
    "    print(inversion, \" # mismatches: \", mismatches,\"\\n\")\n",
    "    print(av_gts)\n",
    "    print(total_sites,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
