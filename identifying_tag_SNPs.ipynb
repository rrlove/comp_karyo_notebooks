{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "from collections import namedtuple\n",
    "import datetime\n",
    "import h5py\n",
    "import ingenos\n",
    "import itertools\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set base directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/afs/crc.nd.edu/group/BesanskyNGS/data05/comp_karyo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in data for 2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_2R, g_2R = ingenos.import_data(\n",
    "    \"/afs/crc.nd.edu/group/BesanskyNGS2/inversion_genotyping/merged_p2_and_VObs_2R.h5\", \"2R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in data for 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_2L = \"/afs/crc.nd.edu/group/BesanskyNGS2/inversion_genotyping/merged_p2_and_VObs_2L.h5\"\n",
    "chrom_2L = \"2L\"\n",
    "\n",
    "callset_2L = h5py.File(path_2L, mode='r')[chrom_2L]\n",
    "\n",
    "v_2L = allel.VariantChunkedTable(callset_2L['variants'], index='POS',\n",
    "                                names=['POS','REF','ALT','DP','MQ','QD','numalt'])\n",
    "\n",
    "g_2L = allel.GenotypeChunkedArray(callset_2L['calldata']['GT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88eacb3d7ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmd_2L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../metadata/all_samples_2L_metadata_080318.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmd_2R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../metadata/all_samples_2R_metadata_080318.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "md_2L = pd.read_csv(base + \"/metadata/all_samples_2L_metadata_080318.csv\", sep=\"\\t\")\n",
    "md_2R = pd.read_csv(base + \"/metadata/all_samples_2R_metadata_080318.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create filters to keep the correct partitions for each inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_outliers = ((md_2R[\"country\"] != \"Kenya\") &\n",
    "                (md_2R[\"country\"] != \"Gambia, The\") &\n",
    "                (md_2R[\"country\"] != \"Guinea-Bissau\")).values\n",
    "\n",
    "west = (md_2R[\"country\"] != \"Kenya\").values\n",
    "\n",
    "j_bool = ((md_2R[\"country\"] != \"Kenya\") & (md_2R[\"country\"] != \"Gambia, The\") &\\\n",
    "          (md_2R[\"country\"] != \"Guinea-Bissau\") & (md_2R[\"country\"] != \"France\") &\\\n",
    "         (md_2R[\"species\"] == \"An. gambiae\")).values\n",
    "\n",
    "col_bool = ( (md_2R[\"ox_code\"].isin(md_2R.loc[non_outliers,\"ox_code\"])) &\\\n",
    "                 (md_2R[\"species\"] == \"An. coluzzii\"))\n",
    "\n",
    "gam_bool = ( (md_2R[\"ox_code\"].isin(md_2R.loc[non_outliers,\"ox_code\"])) &\\\n",
    "                 (md_2R[\"species\"] == \"An. gambiae\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDing tag SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### please note: while the code for all inversions is included here, each section takes a long time to run. I recommend running each inversion separately, and definitely saving at intermediate steps, such as after all ten bootstrap iterations are complete, before averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to identify candidate tag SNPs, the specimens are split into a training and a validation set. the code below includes options for using the sets used in this paper, or for generating one's own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read in the existing identifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = np.load(base + \"/metadata/comp_karyo_splits/splits.npy\").flat[0]\n",
    "\n",
    "splits_d = np.load(base + \"/metadata/comp_karyo_splits/2Rdj_splits.npy\",\n",
    "                allow_pickle=True).flat[0]\n",
    "\n",
    "splits[\"2Rd\"] = splits_d[\"2Rd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ALTERNATE OPTION: generate one's own splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### subset to specimens that could be called for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_2La = pd.DataFrame(md_2L)\n",
    "md_2Rj = md_2R.loc[md_2R[\"new_PCA_2Rj\"] != \"None\",:]\n",
    "md_2Rb = md_2R.loc[md_2R[\"new_PCA_2Rb\"] != \"None\",:]\n",
    "md_2Rc = md_2R.loc[md_2R[\"new_PCA_2Rc\"] != \"None\",:]\n",
    "md_2Rd = md_2R.loc[md_2R[\"new_PCA_2Rd\"] != \"None\",:]\n",
    "md_2Ru = md_2R.loc[md_2R[\"new_PCA_2Ru\"] != \"None\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_splits = {\"2Rb\" : {}, \"2Rc\" : {}, \"2La\" : {}, \"2Rd\" : {}, \"2Ru\" : {}, \"2Rj\" : {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_splits[\"2La\"][\"train\"], own_splits[\"2La\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2La[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2La[\"new_PCA_2La\"].values)\n",
    "\n",
    "own_splits[\"2Rj\"][\"train\"], own_splits[\"2Rj\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rj[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rj[\"new_PCA_2Rj\"].values)\n",
    "\n",
    "own_splits[\"2Rb\"][\"train\"], own_splits[\"2Rb\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rb[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rb[\"new_PCA_2Rb\"].values)\n",
    "\n",
    "own_splits[\"2Rc\"][\"train\"], own_splits[\"2Rc\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rc[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rc[\"new_PCA_2Rc\"].values)\n",
    "\n",
    "own_splits[\"2Rd\"][\"train\"], own_splits[\"2Rd\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Rd[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rd[\"new_PCA_2Rd\"].values)\n",
    "\n",
    "own_splits[\"2Ru\"][\"train\"], own_splits[\"2Ru\"][\"test\"] =\\\n",
    "model_selection.train_test_split(md_2Ru[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Ru[\"new_PCA_2Ru\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### if generating one's own splits, then subsequent references to the \"splits\" object should be replaced with \"own_splits.\" an easy way to do this would be to simply not run the cell in which the \"splits\" object is created, and rename the \"own_splits\" dictionary, at creation, as \"splits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mask low-quality genotypes. We don't do this for PCA, because the results depend on thousands of SNPs. When identifying tag SNPs, however, individual SNPs are the focus and we need to exclude those of low quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2R = h5py.File(\n",
    "    \"/afs/crc.nd.edu/group/BesanskyNGS2/inversion_genotyping/merged_p2_and_VObs_2R.h5\", \n",
    "    mode=\"r\")\n",
    "\n",
    "gq_2R = merged_2R[\"2R\"]['calldata']['GQ'][:]\n",
    "\n",
    "g_2R.mask = gq_2R < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gq_2L = callset_2L['calldata']['GQ'][:]\n",
    "\n",
    "g_2L.mask = gq_2L < 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2La"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2La = ingenos.construct_filter_expression(\"2La\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2La = v_2L.eval(sites_2La)\n",
    "\n",
    "np.sum(filter_2La)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2La = g_2L.subset(sel1 = md_2L[\"ox_code\"].isin(splits[\"2La\"][\"train\"]).values)\n",
    "\n",
    "md_2La = md_2L.loc[md_2L[\"ox_code\"].isin(splits[\"2La\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2La[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2La[\"new_PCA_2La\"].values)\n",
    "    \n",
    "    train_bool = md_2La[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2La[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    a = ingenos.run_concordance_calculation(\"2La\", v_2L[:], g_2La, \n",
    "                                md_2La.loc[train_bool, \"new_PCA_2La\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2La,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = a.loc[((a[\"called_0\"] > 0.9) & (a[\"called_1\"] > 0.9) & (a[\"called_2\"] > 0.9) &\\\n",
    "       (a[\"min\"] > 0.995)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2L[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2La.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2La_test = pd.DataFrame(md_2La.loc[test_bool,:])\n",
    "    \n",
    "    md_2La_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2La_test[\"assigned\"] != md_2La_test[\"new_PCA_2La\"])\n",
    "    \n",
    "    a_dict[i] = (train, test, a, top, mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### average the ten iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    a_compiled.extend(a_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_average = pd.DataFrame({\"position\" : sorted(set(a_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(a_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = a_dict[i][2][a_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    a_average = a_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rj = ingenos.construct_filter_expression(\"2Rj\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rj = v_2R.eval(sites_2Rj)\n",
    "\n",
    "np.sum(filter_2Rj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rj = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"train\"]).values)\n",
    "\n",
    "md_2Rj = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rj\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rj[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rj[\"new_PCA_2Rj\"].values)\n",
    "    \n",
    "    train_bool = md_2Rj[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rj[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    j = ingenos.run_concordance_calculation(\"2Rj\", v_2R[:], g_2Rj, \n",
    "                                md_2Rj.loc[train_bool, \"new_PCA_2Rj\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rj,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = j.loc[((j[\"called_0\"] > 0.9) & (j[\"called_1\"] > 0.9) & (j[\"called_2\"] > 0.9) &\\\n",
    "       (j[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rj.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rj_test = pd.DataFrame(md_2Rj.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rj_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rj_test[\"assigned\"].map(float).map(str) != md_2Rj_test[\"new_PCA_2Rj\"])\n",
    "    \n",
    "    j_dict[i] = (train, test, j, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    j_compiled.extend(j_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_average = pd.DataFrame({\"position\" : sorted(set(j_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(j_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = j_dict[i][2][j_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    j_average = j_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rb = ingenos.construct_filter_expression(\"2Rb\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rb = v_2R.eval(sites_2Rb)\n",
    "\n",
    "np.sum(filter_2Rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rb = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"train\"]).values)\n",
    "\n",
    "md_2Rb = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rb\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rb[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rb[\"new_PCA_2Rb\"].values)\n",
    "    \n",
    "    train_bool = md_2Rb[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rb[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    b = ingenos.run_concordance_calculation(\"2Rb\", v_2R[:], g_2Rb, \n",
    "                                md_2Rb.loc[train_bool, \"new_PCA_2Rb\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rb,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = b.loc[((b[\"called_0\"] > 0.9) & (b[\"called_1\"] > 0.9) & (b[\"called_2\"] > 0.9) &\\\n",
    "       (b[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rb.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rb_test = pd.DataFrame(md_2Rb.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rb_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rb_test[\"assigned\"].map(float).map(str) != md_2Rb_test[\"new_PCA_2Rb\"])\n",
    "    \n",
    "    b_dict[i] = (train, test, b, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    b_compiled.extend(b_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_average = pd.DataFrame({\"position\" : sorted(set(b_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(b_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = b_dict[i][2][b_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    b_average = b_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we identified concordant SNPs separetely in coluzzii and gambiae in 2Rc. in addition, we dropped specimens that carried 2Ru in gambiae, which were outliers on the PCA, from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rc = ingenos.construct_filter_expression(\"2Rc\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Rc = v_2R.eval(sites_2Rc)\n",
    "\n",
    "np.sum(filter_2Rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rc = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"train\"]).values)\n",
    "\n",
    "md_2Rc = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rc\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### coluzzii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_bool = (md_2Rc[\"species\"] == \"An. coluzzii\").values\n",
    "\n",
    "col_c = g_2Rc.subset(sel1 = col_bool)\n",
    "\n",
    "col_md = md_2Rc.loc[col_bool,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(col_md[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=col_md[\"new_PCA_2Rc\"].values)\n",
    "    \n",
    "    train_bool = col_md[\"ox_code\"].isin(train).values\n",
    "    test_bool = col_md[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    col_c_conc = ingenos.run_concordance_calculation(\"2Rc\", v_2R[:], col_c, \n",
    "                                col_md.loc[train_bool, \"new_PCA_2Rc\"].map(int).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rc,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = col_c_conc.loc[((col_c_conc[\"called_0\"] > 0.9) &\\\n",
    "                     (col_c_conc[\"called_1\"] > 0.9) &\\\n",
    "                     (col_c_conc[\"called_2\"] > 0.9) &\\\n",
    "       (col_c_conc[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = col_c.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    col_md_test = pd.DataFrame(col_md.loc[test_bool,:])\n",
    "    \n",
    "    col_md_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(col_md_test[\"assigned\"].map(str) != col_md_test[\"new_PCA_2Rc\"])\n",
    "    \n",
    "    col_c_dict[i] = (train, test, col_c_conc, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    col_c_compiled.extend(col_c_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_c_average = pd.DataFrame({\"position\" : sorted(set(col_c_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = col_c_dict[i][2][col_c_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "    \n",
    "    #print(pos, mean_row)\n",
    "    \n",
    "    col_c_average = col_c_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gambiae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_trim_bool = ((md_2Rc[\"species\"] == \"An. gambiae\") &\\\n",
    "                 (md_2Rc[\"new_PCA_2Rj\"] != \"2.0\") &\\\n",
    "                 (md_2Rc[\"ox_code\"] != \"AZ0267-C\") &\\\n",
    "                (md_2Rc[\"ox_code\"] != \"AV0043-C\")).values\n",
    "\n",
    "gam_c = g_2Rc.subset(sel1 = gam_trim_bool)\n",
    "\n",
    "gam_md = md_2Rc.loc[gam_trim_bool,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(gam_md[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=gam_md[\"new_PCA_2Rc\"].values)\n",
    "    \n",
    "    train_bool = gam_md[\"ox_code\"].isin(train).values\n",
    "    test_bool = gam_md[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    gam_c_conc = ingenos.run_concordance_calculation(\"2Rc\", v_2R[:], gam_c, \n",
    "                                gam_md.loc[train_bool, \"new_PCA_2Rc\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rc,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = gam_c_conc.loc[((gam_c_conc[\"called_0\"] > 0.9) &\\\n",
    "                     (gam_c_conc[\"called_1\"] > 0.9) &\\\n",
    "                     (gam_c_conc[\"called_2\"] > 0.9) &\\\n",
    "       (gam_c_conc[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = gam_c.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    gam_md_test = pd.DataFrame(gam_md.loc[test_bool,:])\n",
    "    \n",
    "    gam_md_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(gam_md_test[\"assigned\"].map(str) != gam_md_test[\"new_PCA_2Rc\"])\n",
    "    \n",
    "    gam_c_dict[i] = (train, test, gam_c_conc, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    gam_c_compiled.extend(gam_c_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gam_c_average = pd.DataFrame({\"position\" : sorted(set(gam_c_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(gam_c_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = gam_c_dict[i][2][gam_c_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "    \n",
    "    #print(pos, mean_row)\n",
    "    \n",
    "    gam_c_average = gam_c_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for identifying concordant SNPs in 2Rd, we use the entire inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Rd = '( (POS > 31495381) & (POS < 42375004) )'\n",
    "\n",
    "filter_2Rd = v_2R.eval(sites_2Rd)\n",
    "\n",
    "np.sum(filter_2Rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Rd = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"train\"]).values)\n",
    "\n",
    "md_2Rd = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Rd\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Rd[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Rd[\"new_PCA_2Rd\"].values)\n",
    "    \n",
    "    train_bool = md_2Rd[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Rd[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    d = ingenos.run_concordance_calculation(\"2Rd\", v_2R[:], g_2Rd, \n",
    "                                md_2Rd.loc[train_bool, \"new_PCA_2Rd\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Rd,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = d.loc[((d[\"called_0\"] > 0.9) & (d[\"called_1\"] > 0.9) & (d[\"called_2\"] > 0.9) &\\\n",
    "       (d[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Rd.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Rd_test = pd.DataFrame(md_2Rd.loc[test_bool,:])\n",
    "    \n",
    "    md_2Rd_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Rd_test[\"assigned\"].map(float).map(str) != md_2Rd_test[\"new_PCA_2Rd\"])\n",
    "    \n",
    "    d_dict[i] = (train, test, d, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    d_compiled.extend(d_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_average = pd.DataFrame({\"position\" : sorted(set(d_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(d_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = d_dict[i][2][d_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    d_average = d_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2Ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites_2Ru = ingenos.construct_filter_expression(\"2Ru\", ingenos.inversionDict,\n",
    "                                                buffer=0, whole_inversion=True)\n",
    "\n",
    "filter_2Ru = v_2R.eval(sites_2Ru)\n",
    "\n",
    "np.sum(filter_2Ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_2Ru = g_2R.subset(sel1 = md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"train\"]).values)\n",
    "\n",
    "md_2Ru = md_2R.loc[md_2R[\"ox_code\"].isin(splits[\"2Ru\"][\"train\"]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    train, test =\\\n",
    "    model_selection.train_test_split(md_2Ru[\"ox_code\"].values, train_size=0.75, test_size=0.25,\n",
    "                                 stratify=md_2Ru[\"new_PCA_2Ru\"].values)\n",
    "    \n",
    "    train_bool = md_2Ru[\"ox_code\"].isin(train).values\n",
    "    test_bool = md_2Ru[\"ox_code\"].isin(test).values\n",
    "    \n",
    "    u = ingenos.run_concordance_calculation(\"2Ru\", v_2R[:], g_2Ru, \n",
    "                                md_2Ru.loc[train_bool, \"new_PCA_2Ru\"].map(float).values,\n",
    "                                        variance_threshold = 0.05, sites_bool = filter_2Ru,\n",
    "                                samples_bool = train_bool)\n",
    "    \n",
    "    top = u.loc[((u[\"called_0\"] > 0.9) & (u[\"called_1\"] > 0.9) & (u[\"called_2\"] > 0.9) &\\\n",
    "       (u[\"min\"] > 0.8)),\"position\"].values\n",
    "    \n",
    "    site_indices = np.array([np.where(v_2R[\"POS\"] == site)[0][0] for site in top])\n",
    "\n",
    "    alts = g_2Ru.subset(sel0 = site_indices, sel1 = test_bool).to_n_alt()\n",
    "    \n",
    "    assigned = []\n",
    "\n",
    "    for specimen in np.mean(alts, axis=0):\n",
    "        \n",
    "        if specimen <= 0.66:\n",
    "        \n",
    "            assigned.append(0)\n",
    "        \n",
    "        elif specimen > 0.66 and specimen <= 1.33:\n",
    "\n",
    "            assigned.append(1)\n",
    "\n",
    "        else:\n",
    "\n",
    "            assigned.append(2)\n",
    "            \n",
    "    md_2Ru_test = pd.DataFrame(md_2Ru.loc[test_bool,:])\n",
    "    \n",
    "    md_2Ru_test[\"assigned\"] = pd.Series(assigned).values\n",
    "    \n",
    "    mismatches =\\\n",
    "    np.sum(md_2Ru_test[\"assigned\"].map(str) != md_2Ru_test[\"new_PCA_2Ru\"])\n",
    "    \n",
    "    u_dict[i] = (train, test, u, top, mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_compiled = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    u_compiled.extend(u_dict[i][2][\"position\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_average = pd.DataFrame({\"position\" : sorted(set(u_compiled)),\n",
    "                          \"ref\" : np.nan,\n",
    "                          \"alt\" : np.nan,\n",
    "                         \"score_0\" : np.nan, \n",
    "                          \"score_1\" : np.nan, \n",
    "                          \"score_2\" : np.nan,\n",
    "                         \"overall_score\" : np.nan, \n",
    "                          \"called_0\" : np.nan, \n",
    "                          \"called_1\" : np.nan,\n",
    "                         \"called_2\" : np.nan, \n",
    "                          \"overall_called\" : np.nan, \n",
    "                          \"min\" : np.nan})\\\n",
    "[[\"position\",\"ref\",\"alt\",\"score_0\",\"score_1\",\"score_2\",\"overall_score\",\"called_0\",\"called_1\",\n",
    " \"called_2\",\"overall_called\",\"min\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in sorted(set(u_compiled)):\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    refs = []\n",
    "    \n",
    "    alts = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        row = u_dict[i][2][u_dict[i][2][\"position\"] == pos]\n",
    "\n",
    "        if len(row) > 0:\n",
    "            \n",
    "            refs.append(row[\"ref\"].values[0])\n",
    "            \n",
    "            alts.append(row[\"alt\"].values[0])\n",
    "\n",
    "            rows[i] = row.drop([\"ref\",\"alt\"], axis=1).reset_index(drop=True)\n",
    "            \n",
    "    if not len(set(refs)) == 1 and len(set(alts)) == 1:\n",
    "        \n",
    "        raise ValueError(pos, rows)\n",
    "        \n",
    "    ref = refs[0]\n",
    "    \n",
    "    alt = alts[0]\n",
    "\n",
    "    mean_row = np.sum(rows[i] for i in rows.keys()) / len(rows.keys())\n",
    "    \n",
    "    mean_row[\"count\"] = len(rows.keys())\n",
    "    \n",
    "    mean_row[\"ref\"] = ref\n",
    "    \n",
    "    mean_row[\"alt\"] = alt\n",
    "    \n",
    "    assert mean_row[\"position\"].values[0] == pos, row\n",
    "        \n",
    "    u_average = u_average.append(mean_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### take the top SNPs for each inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_top = a_average.loc[((a_average[\"called_0\"] > 0.9) & (a_average[\"called_1\"] > 0.9) &\\\n",
    "                       (a_average[\"called_2\"] > 0.9) &\\\n",
    "               (a_average[\"min\"] > 0.995) & (a_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j_top = j_average.loc[((j_average[\"called_0\"] > 0.9) & (j_average[\"called_1\"] > 0.9) &\\\n",
    "                       (j_average[\"called_2\"] > 0.9) &\\\n",
    "               (j_average[\"min\"] > 0.8) & (j_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_top = b_average.loc[((b_average[\"called_0\"] > 0.9) & (b_average[\"called_1\"] > 0.9) &\\\n",
    "                       (b_average[\"called_2\"] > 0.9) &\\\n",
    "               (b_average[\"min\"] > 0.8) & (b_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_col_top = col_average.loc[((col_average[\"called_0\"] > 0.9) &\\\n",
    "                             (col_average[\"called_1\"] > 0.9) &\\\n",
    "                         (col_average[\"called_2\"] > 0.9) &\\\n",
    "               (col_average[\"min\"] > 0.8) & (col_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_gam_top = gam_average.loc[((gam_average[\"called_0\"] > 0.9) &\\\n",
    "                             (gam_average[\"called_1\"] > 0.9) &\\\n",
    "                         (gam_average[\"called_2\"] > 0.9) &\\\n",
    "               (gam_average[\"min\"] > 0.8) & (gam_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_top = d_average.loc[((d_average[\"called_0\"] > 0.9) & (d_average[\"called_1\"] > 0.9) &\\\n",
    "                       (d_average[\"called_2\"] > 0.9) &\\\n",
    "               (d_average[\"min\"] > 0.8) & (d_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_top = u_average.loc[((u_average[\"called_0\"] > 0.9) & (u_average[\"called_1\"] > 0.9) &\\\n",
    "                       (u_average[\"called_2\"] > 0.9) &\\\n",
    "               (u_average[\"min\"] > 0.8) & (u_average[\"count\"] >= 8)), \"position\"].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save the top SNPs to the desired location as in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2La/comp/predictive_SNPs_train_set_0995\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "j_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Rj/comp/predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "b_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Rb/comp/predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "c_col_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Rc/comp/col_predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "c_gam_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Rc/comp/gam_predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "d_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Rd/comp/predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)\n",
    "\n",
    "u_top.to_csv(ingenos.make_date_stamp(base + \"/data/results/2Ru/comp/predictive_SNPs_train_set_08\", \".tsv\"),\n",
    "            sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
